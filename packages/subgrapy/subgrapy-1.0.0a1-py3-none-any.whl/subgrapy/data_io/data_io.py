import os
from datetime import datetime
from typing import Optional
from gql import gql, Client
from gql.transport.requests import RequestsHTTPTransport

from .subgraphs import SubGraphs


def subgraph_client(subgraph_type: str) -> 'DataFrame':
    """Reads data from subgraphs.

    Args:
        subgraph_type: the name of the dataset to read (refer to the names in the docstring)

    Returns:
        A PySpark DataFrame read from HDFS

    Supported subgraphs:
        graphprotocol:
            graphprotocol:mainnet
            graphprotocol:dev
            graphprotocol:analytics

    **Example**

    .. code-block:: python

        from subgrapy import data_io

        client = data_io.subgraph_client(subgraph_type='mainnet')
    """
    subgraph_name = SubGraphs.graphprotocol
    subgraph_url = subgraph_name[subgraph_type]['url']

    sample_transport = RequestsHTTPTransport(url=subgraph_url,
                                             verify=True,
                                             retries=5)

    client = Client(transport=sample_transport)

    return client


def generate_path_to_write(environment: str,
                           granularity: str,
                           subgraph_name: str,
                           root_path: str = '/subgrapy',
                           timestamp: Optional[str] = None):
    """Generates an HDFS path from the inputs.
    The output path is of the form ``/ROOT_PATH/ENVIRONMENT/GRANULARITY/DATASET_NAME/TIMESTAMP``

    Args:
        environment: possible values are 'dev' or 'prod'
        granularity: possible values are 'stream', 'minute', 'daily', 'weekly', 'monthly'
        subgraph_name: the name of the dataset, with no spaces e.g. stock_ticker_metadata
        root_path: the root for your dataset path, e.g. ``/user/your_user`` or ``/group/subgrapy``.
        Defaults to ``/group/subgrapy``.
        experiment_id: the unique identifer for the experiment
        timestamp: the timestamp in UTC when the job ran, autogenerated. Can be overridden e.g. if user wants to
                   pass in some id like 'v1' or 'run10' or 'run_with_fixes'.

    Returns:
        The path to be written to

    **Example**
    .. code-block:: python

        from subgrapy import data_io
        data_io.generate_path_to_write(
            environment='dev',
            granularity='daily',
            subgraph_name='graphprotocol'
        )
        # /subgrapy/dev/aggregate/graphprotocol/file1.csv...file2.csv
    """
    supported_environments = ['dev', 'prod']
    supported_granularities = ['stream', 'minute', 'daily', 'weekly', 'monthly']

    if environment not in supported_environments or granularity not in supported_granularities:
        raise ValueError('Unsupported environment or granularity.')

    subgraph_name = subgraph_name.replace(' ', '_').lower()
    timestamp = timestamp or datetime.utcnow().strftime('%Y-%m-%d_%H-%M-%S')

    return os.path.join(root_path, environment, granularity, subgraph_name, timestamp)

