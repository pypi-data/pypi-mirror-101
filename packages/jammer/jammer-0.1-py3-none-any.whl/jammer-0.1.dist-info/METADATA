Metadata-Version: 2.1
Name: jammer
Version: 0.1
Summary: Library for jax based affine-invariant MCMC sampling
Home-page: https://github.com/utkarshgiri/jammer
Author: Utkarsh Giri
Author-email: utkarshgiri@gmail.com
License: MIT License
Project-URL: Bug Tracker, https://github.com/utkarshgiri/jammer/issues
Keywords: jax,MCMC,affine-invariant,goodman-weare,sampler
Platform: UNKNOWN
Requires-Python: >=3.6
Requires-Dist: jax (>=0.2.12)
Requires-Dist: jaxlib (>=0.1.64)
Requires-Dist: absl-py (>=0.12.0)
Requires-Dist: numpy (>=1.18)
Requires-Dist: tqdm (>=4.50)
Requires-Dist: joblib (>=0.17)
Requires-Dist: matplotlib (>=3.3)
Requires-Dist: corner (>=2.2)
Requires-Dist: emcee (>=3.0)
Requires-Dist: scipy (>=1.6.2)
Requires-Dist: kiwisolver (>=1.3.1)

# jammer

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) 
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

A jax based affine-invariant MCMC hammer that can leverage GPUs to speed up sampling for computationally intensive likelihoods. It implements the [Goodman-Weare](https://msp.org/camcos/2010/5-1/p04.xhtml) algorithm as described in [dfm++](https://arxiv.org/abs/1202.3665) and is inspired by the popular [`emcee`](https://github.com/dfm/emcee) library. The `just-in-time` compilation together with `vectorized` likelihood evaluation for the walkers gives significant speed-up even on CPUs when compared to emcee

## Installation

To install `jammer`, please clone this repository and then run `python setup.py install` inside it \
You can also install this via `pip` using
```
pip install jammer
```
To run it on a GPU, you must have an installation of `jaxlib` compatible with your CUDA version. For more information, please refer to the official [guidelines](https://github.com/google/jax#installation) 

The API for `jammer` is slightly different from `emcee`. This might change in the future.


