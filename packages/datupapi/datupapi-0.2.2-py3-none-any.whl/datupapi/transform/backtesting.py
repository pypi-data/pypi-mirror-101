import boto3
import numpy as np
import os
import pandas as pd

from datupapi.configure.config import Config
from datupapi.extract.io import IO

class Backtesting(Config):

    def __init__(self, config_file, logfile, log_path, *args, **kwargs):
        Config.__init__(self, config_file=config_file, logfile=logfile)
        self.log_path = log_path


    def concat_backtests_export(self, datalake_path_=None, intervals_fill=None):
        """
        Return a dataframe including all backtests partitions generated by create_predictor_backtest_export API's calling

        :param datalake_path: Datalake path to the backtests' partitions files
        :param intervals_fill: List of intevals to fill with -9999, since no usage (e.g. ['Lo95', 'Up95'])
        :return df_backtests: Dataframe concatenating all backtests estimates

        >>> df = concat_backtests_export(datalake_path_='/path/to/backtests', intervals_fill=['Lo95', 'Up95'])
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        df_backtests = pd.DataFrame()
        try:
            for part in range(0, 25):
                df_tmp = io.download_object(datalake_path=datalake_path_ + str(part) + '.csv')
                df_backtests = pd.concat([df_backtests, df_tmp], axis='rows')
            for col in ['timestamp', 'backtestwindow_start_time', 'backtestwindow_end_time']:
                df_backtests[col] = pd.to_datetime(df_backtests[col], format='%Y-%m-%d')
            df_backtests = df_backtests.rename(columns={'item_id': 'Item',
                                                        'timestamp': 'Date',
                                                        'target_value': 'Target',
                                                        'p5': 'Forecast Lo95',
                                                        'p20': 'Forecast Lo80',
                                                        'p40': 'Forecast Lo60',
                                                        'p50': 'Forecast Point',
                                                        'p60': 'Forecast Up60',
                                                        'p70': 'Forecast Up80',
                                                        'p95': 'Forecast Up95'
                                                        }
                                               )
            for interval in intervals_fill:
                df_backtests['Forecast ' + interval] = -9999
            forecast_cols = [col for col in df_backtests.columns if all(subcol not in col for subcol in ['Item', 'Date', 'Target'])]
            df_backtests[forecast_cols] = df_backtets[forecast_cols].applymap(lambda x: 0 if x < 0 else x)\
                                                                  .applymap(lambda x: round(x))
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_backtests


    def create_backtest_dataset(self, df_backtests, backtest_name=None):
        """
        Return a dataframe containing the dates, items and backtesting forecasts for a specific backtest

        :param df_backtests: Dataframe including backtests partitions concatenated
        :param backtest_name: Backtests name to distinguish oldest to newest backtest dataset. Choose from alpha, beta, gamma & delta
        :return df_back: Dataframe including dates, items and back forecasts for the specified period

        >>> df = create_backtest_dataset(df_backtests, backtest_name='alpha')
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        if backtest_name == 'alpha':
            date_ix = 3
        elif backtest_name == 'beta':
            date_ix = 2
        elif backtest_name == 'gamma':
            date_ix = 1
        elif backtest_name == 'delta':
            date_ix = 0
        else:
            self.logger.exception(f'No valid backtest name. Choose from alpha, beta, gamma or delta.')

        try:
            mask_start = df_backtests['backtestwindow_start_time'] == pd.to_datetime(np.sort(df_backs['backtestwindow_start_time'].unique())[date_ix])
            mask_end = df_backtests['backtestwindow_end_time'] == pd.to_datetime(np.sort(df_backs['backtestwindow_end_time'].unique())[date_ix])
            df_back = df_backtests[(mask_start) & (mask_end)].drop(['backtestwindow_start_time', 'backtestwindow_end_time'], axis='columns')
            df_back = df_back[['Date', 'Item', 'Target',
                               'Forecast Point', 'Forecast Lo95', 'Forecast Lo80', 'Forecast Lo60',
                               'Forecast Up60', 'Forecast Up80', 'Forecast Up95']].sort_values(['Date'], ascending=False)
            df_back['Week'] = df_back['Date'].dt.isocalendar()['week']
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_back


    def compute_bias(self, df_back):
        """
        Return a dataframe including the bias between target value and each forecast interval

        :param df_back: Original backtest dataframe
        :return df_back: Backtest dataframe including bias column for each forecast interval

        >>> df = compute_bias(df)
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        try:
            for bias in ['Point', 'Lo95', 'Lo80', 'Lo60', 'Up60', 'Up80', 'Up95']:
                df_back['Bias ' + bias] =  abs(df_back['Target'] - df_back['Forecast ' + bias])
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_back


    def compute_tracking_bias(self, df_back):
        """
        Return a dataframe including the tracking bias for each date

        :param df_back: Original backtest dataframe
        :return df_back: Backtest dataframe including tracking bias column for each date

        >>> df = compute_tracking_bias(df)
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        try:
            bias_cols = ['Bias Point', 'Bias Lo95', 'Bias Lo80', 'Bias Lo60', 'Bias Up60', 'Bias Up80', 'Bias Up95']
            df_back['Tracking Bias'] = df_back[bias_cols].idxmin(axis='columns')\
                                                         .str.strip('Bias ')
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_back


    def compute_tracked_bias(self, df_back):
        """
        Return a dataframe including the tracked bias for each item

        :param df_back: Original backtest dataframe
        :return df_back: Backtest dataframe including tracking bias column for each item

        >>> df = compute_tracked_bias(df)
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        try:
            for item in df_back['Item']:
                mask = df_back['Item'] == item
                df_back.loc[mask, 'Suggested Interval'] = df_back.loc[mask, 'Tracking Bias']\
                                                                 .value_counts()\
                                                                 .index[0]
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_back


    def compute_tracked_bias_forecast(self, df_back):
        """
        Return a dataframe including the tracked bias forecast for each item and date

        :param df_back: Original backtest dataframe
        :return df_back: Backtest dataframe including tracking bias column for each item and date

        >>> df = compute_tracked_bias_forecast(df)
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        try:
            tracked_bias_forescast = []
            for row_ix, row in df_back.iterrows():
                tracked_bias_forescast.append(row['Forecast ' + row['Suggested Interval']])
            df_back['Suggested Forecast'] = tracked_bias_forescast
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_back


    def compute_tracked_bias_error(self, df_back, error_type='WMAPE'):
        """
        Return a dataframe including the specified forecast error between target and tracked bias forecast

        :param df_back: Original backtest dataframe
        :param error_type: Forecast error to compute among sMAPE, MASE, WMAPE, MAPE, WAPE, RMSE, etc. Default WMAPE.
        :return df_back: Backtest dataframe including tracking bias column for each item and date

        >>> df = compute_tracked_bias_error(df, error_type='MAPE')
        >>> df =
                        var1    var2    var3
                idx0     1       2       3
        """
        try:
            for item in df_back['Item']:
                mask = df_back['Item'] = item
                forecast_col = 'Forecast ' + df_back.loc[mask, 'Tracked Bias'].values[0]
                target_ts = df_back.loc[mask, 'Target'].values
                forecast_ts = df_back.loc[mask, forecast_col].values
                if error_type == 'sMAPE':
                    df_back.loc[mask, error_type] = round(frr.compute_smape(target_ts, forecast_ts), 2)
                elif error_type == 'WMAPE':
                    df_back.loc[mask, error_type] = round(frr.compute_wmape(target_ts, forecast_ts), 2)
                elif error_type == 'MASE':
                    df_back.loc[mask, error_type] = round(frr.compute_mase(target_ts, forecast_ts), 2)
                elif error_type == 'WAPE':
                    df_back.loc[mask, error_type] = round(frr.compute_wape(target_ts, forecast_ts), 2)
                elif error_type == 'RMSE':
                    df_back.loc[mask, error_type] = round(frr.compute_rmse(target_ts, forecast_ts), 2)
                else:
                    self.logger.exception(f'No valid forecast error name. Choose from sMAPE, WMAPE, MASE, WAPE, RMSE')
                df_back = df_back.replace([np.inf, -np.inf], np.nan)
                df_back = df_back.fillna(0)
        except KeyError as err:
            self.logger.exception(f'Invalid column name. Please check dataframe metadata: {err}')
            raise
        return df_back

