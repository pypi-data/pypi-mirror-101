# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['fate_test', 'fate_test.flow_test', 'fate_test.scripts']

package_data = \
{'': ['*']}

install_requires = \
['click>=7.1.2,<8.0.0',
 'colorama>=0.4.4,<0.5.0',
 'fate_client==0.3.0.post1',
 'loguru>=0.5.1,<0.6.0',
 'pandas>=1.1.5',
 'prettytable>=1.0.0,<2.0.0',
 'requests>=2.24.0,<3.0.0',
 'requests_toolbelt>=0.9.1,<0.10.0',
 'ruamel.yaml>=0.16.10,<0.17.0',
 'sshtunnel>=0.1.5,<0.2.0']

entry_points = \
{'console_scripts': ['fate_test = fate_test.scripts.cli:cli']}

setup_kwargs = {
    'name': 'fate-test',
    'version': '0.3.0.post1',
    'description': 'test tools for FATE',
    'long_description': 'FATE Test\n=========\n\nA collection of useful tools to running FATE\'s test.\n\n.. image:: images/tutorial.gif\n   :align: center\n   :alt: tutorial\n\nquick start\n-----------\n\n1. (optional) create virtual env\n\n   .. code-block:: bash\n\n      python -m venv venv\n      source venv/bin/activate\n      pip install -U pip\n\n\n2. install fate_test\n\n   .. code-block:: bash\n\n      pip install fate_test\n      fate_test --help\n\n\n3. edit default fate_test_config.yaml\n\n   .. code-block:: bash\n\n      # edit priority config file with system default editor\n      # filling some field according to comments\n      fate_test config edit\n\n4. configure FATE-Pipeline and FATE-Flow Commandline server setting\n\n.. code-block:: bash\n\n      # configure FATE-Pipeline server setting\n      pipeline init --port 9380 --ip 127.0.0.1\n      # configure FATE-Flow Commandline server setting\n      flow init --port 9380 --ip 127.0.0.1\n\n5. run some fate_test suite\n\n   .. code-block:: bash\n\n      fate_test suite -i <path contains *testsuite.json>\n\n\n6. run some fate_test benchmark\n\n   .. code-block:: bash\n\n      fate_test benchmark-quality -i <path contains *benchmark.json>\n\n7. useful logs or exception will be saved to logs dir with namespace shown in last step\n\ndevelop install\n---------------\nIt is more convenient to use the editable mode during development: replace step 2 with flowing steps\n\n.. code-block:: bash\n\n   pip install -e ${FATE}/python/fate_client && pip install -e ${FATE}/python/fate_test\n\n\n\ncommand types\n-------------\n\n- suite: used for running testsuites, collection of FATE jobs\n\n  .. code-block:: bash\n\n     fate_test suite -i <path contains *testsuite.json>\n\n\n- benchmark-quality used for comparing modeling quality between FATE and other machine learning systems\n\n  .. code-block:: bash\n\n      fate_test bq -i <path contains *benchmark.json>\n\n\n\nconfiguration by examples\n--------------------------\n\n1. no need ssh tunnel:\n\n   - 9999, service: service_a\n   - 10000, service: service_b\n\n   and both service_a, service_b can be requested directly:\n\n   .. code-block:: yaml\n\n      work_mode: 1 # 0 for standalone, 1 for cluster\n      data_base_dir: <path_to_data>\n      parties:\n        guest: [10000]\n        host: [9999, 10000]\n        arbiter: [9999]\n      services:\n        - flow_services:\n          - {address: service_a, parties: [9999]}\n          - {address: service_b, parties: [10000]}\n\n2. need ssh tunnel:\n\n   - 9999, service: service_a\n   - 10000, service: service_b\n\n   service_a, can be requested directly while service_b don\'t,\n   but you can request service_b in other node, say B:\n\n   .. code-block:: yaml\n\n      work_mode: 0 # 0 for standalone, 1 for cluster\n      data_base_dir: <path_to_data>\n      parties:\n        guest: [10000]\n        host: [9999, 10000]\n        arbiter: [9999]\n      services:\n        - flow_services:\n          - {address: service_a, parties: [9999]}\n        - flow_services:\n          - {address: service_b, parties: [10000]}\n          ssh_tunnel: # optional\n          enable: true\n          ssh_address: <ssh_ip_to_B>:<ssh_port_to_B>\n          ssh_username: <ssh_username_to B>\n          ssh_password: # optional\n          ssh_priv_key: "~/.ssh/id_rsa"\n\n\nTestsuite\n---------\n\nTestsuite is used for running a collection of jobs in sequence. Data used for jobs could be uploaded before jobs are\nsubmitted and, optionally, be cleaned after jobs finish. This tool is useful for FATE\'s release test.\n\ncommand options\n~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n      fate_test suite --help\n\n1. include:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json>\n\n   will run testsuites in *path1*\n\n2. exclude:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -e <path2 to exclude> -e <path3 to exclude> ...\n\n   will run testsuites in *path1* but not in *path2* and *path3*\n\n3. glob:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -g "hetero*"\n\n   will run testsuites in sub directory start with *hetero* of *path1*\n\n4. replace:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -r \'{"maxIter": 5}\'\n\n   will find all key-value pair with key "maxIter" in `data conf` or `conf` or `dsl` and replace the value with 5\n\n5. timeout:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -m 3600\n\n   will run testsuites in *path1* and timeout when job does not finish within 3600s; if tasks need more time, use a larger threshold\n\n6. task-cores\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -p 4\n\n   will run testsuites in *path1* with EGGROLL "task-cores" set to 4; only effective for DSL conf\n\n7. update-job-parameters\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -j {}\n\n   will run testsuites in *path1* with respective job parameters set to provided values\n\n8. update-component-parameters\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> -c {}\n\n   will run testsuites in *path1* with respective component parameters set to provided values\n\n9. skip-dsl-jobs:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json> --skip-dsl-jobs\n\n   will run testsuites in *path1* but skip all *tasks* in testsuites. It\'s would be useful when only pipeline tasks needed.\n\n10. skip-pipeline-jobs:\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json> --skip-pipeline-jobs\n\n    will run testsuites in *path1* but skip all *pipeline tasks* in testsuites. It\'s would be useful when only dsl tasks needed.\n\n11. skip-data:\n\n    .. code-block:: bash\n\n        fate_test suite -i <path1 contains *testsuite.json> --skip-data\n\n    will run testsuites in *path1* without uploading data specified in *testsuite.json*.\n\n12. data only:\n\n    .. code-block:: bash\n\n        fate_test suite -i <path1 contains *testsuite.json> --data-only\n\n    will only upload data specified in *testsuite.json* without running jobs\n\n13. disable-clean-data:\n\n    .. code-block:: bash\n\n        fate_test suite -i <path1 contains *testsuite.json> --disable-clean-data\n\n    will run testsuites in *path1* without removing data from storage after tasks finish\n\n14. enable-clean-data:\n\n    .. code-block:: bash\n\n        fate_test suite -i <path1 contains *testsuite.json> --enable-clean-data\n\n    will remove data from storage after finishing running testsuites\n\n15. yes:\n\n    .. code-block:: bash\n\n        fate_test suite -i <path1 contains *testsuite.json> --yes\n\n    will run testsuites in *path1* directly, skipping double check\n\ntestsuite\n~~~~~~~~~\n\nConfiguration of jobs should be specified in a testsuite whose file name ends\nwith "\\*testsuite.json". For testsuite examples,\nplease refer `dsl examples <../../examples/dsl/v2>`_ and `pipeline examples <../../examples/dsl/pipeline>`_.\n\nA testsuite includes the following elements:\n\n- data: list of local data to be uploaded before running FATE jobs\n\n  - file: path to original data file to be uploaded, should be relative to testsuite or FATE installation path\n  - head: whether file includes header\n  - partition: number of partition for data storage\n  - table_name: table name in storage\n  - namespace: table namespace in storage\n  - role: which role to upload the data, as specified in fate_test.config;\n    naming format is: "{role_type}_{role_index}", index starts at 0\n\n  .. code-block:: json\n\n        "data": [\n            {\n                "file": "examples/data/motor_hetero_host.csv",\n                "head": 1,\n                "partition": 8,\n                "table_name": "motor_hetero_host",\n                "namespace": "experiment",\n                "role": "host_0"\n            }\n        ]\n\n- tasks: includes arbitrary number of jobs with paths to corresponding dsl and conf files\n\n  - job: name of job to be run, must be unique within each group list\n\n    - conf: path to conf filw, should be relative to testsuite\n    - dsl: path to dsl file, should be relative to testsuite\n\n    .. code-block:: json\n\n       "tasks": {\n            "cv": {\n                "conf": "hetero_lr_cv_conf.json",\n                "dsl": "hetero_lr_cv_dsl.json"\n            },\n            "early-stop": {\n                "conf": "hetero_lr_early_stop_conf.json",\n                "dsl": "hetero_lr_early_stop_dsl.json"\n            }\n       }\n\n- pipeline_tasks: includes arbitrary number of pipeline jobs with paths to corresponding python script\n\n  - job: name of job to be run, must be unique within each group list\n\n    - script: path to pipeline script, should be relative to testsuite\n\n    .. code-block:: json\n\n       "pipeline_tasks": {\n            "cv": {\n                "script": "pipeline-hetero-lr-cv.py"\n            },\n            "normal": {\n                "script": "pipeline-hetero-lr-early-stop.py"\n            }\n       }\n\n  - model_deps(deps): model to be used for prediction task\n\n    .. code-block:: json\n\n       "tasks": {\n            "cv": {\n                "conf": "hetero_lr_cv_conf.json",\n                "dsl": "hetero_lr_cv_dsl.json"\n            },\n            "normal": {\n                "conf": "hetero_lr_normal_conf.json",\n                "dsl": "hetero_lr_normal_dsl.json"\n            },\n            "predict": {\n            "conf": "hetero-lr-normal-predict-conf.json",\n            "dsl": "hetero-lr-normal-predict-dsl.json",\n            "deps": "normal"\n            }\n       }\n\n\n  - data_deps: component output data from previous task to be used as designated input for current task(only used for dsl tasks)\n\n    .. code-block:: json\n\n        "tasks": {\n        "column-expand": {\n            "conf": "./test_column_expand_job_conf.json",\n            "dsl": "./test_column_expand_job_dsl.json"\n        },\n        "column-expand-train": {\n            "conf": "./test_column_expand_train_job_conf.json",\n            "dsl": "./test_column_expand_train_job_dsl.json",\n            "data_deps": {\n                "column-expand": {\n                    "guest_0": {\n                        "reader_0": "column_expand_0"\n                        }\n                    }\n                }\n            }\n        }\n\n\n\nBenchmark Quality\n------------------\n\nBenchmark-quality is used for comparing modeling quality between FATE\nand other machine learning systems. Benchmark produces a metrics comparison\nsummary for each benchmark job group.\n\nBenchmark can also compare metrics of different models from the same script/PipeLine job.\nPlease refer to the `script writing guide <#testing-script>`_ below for instructions.\n\n.. code-block:: bash\n\n   fate_test benchmark-quality -i examples/benchmark_quality/hetero_linear_regression\n\n.. code-block:: bash\n\n     |----------------------------------------------------------------------|\n     |                             Data Summary                             |\n     |-------+--------------------------------------------------------------|\n     |  Data |                         Information                          |\n     |-------+--------------------------------------------------------------|\n     | train | {\'guest\': \'motor_hetero_guest\', \'host\': \'motor_hetero_host\'} |\n     |  test | {\'guest\': \'motor_hetero_guest\', \'host\': \'motor_hetero_host\'} |\n     |-------+--------------------------------------------------------------|\n\n\n     |-------------------------------------------------------------------------------------------------------------------------------------|\n     |                                                           Metrics Summary                                                           |\n     |-------------------------------------------+-------------------------+--------------------+---------------------+--------------------|\n     |                 Model Name                | root_mean_squared_error |      r2_score      |  mean_squared_error | explained_variance |\n     |-------------------------------------------+-------------------------+--------------------+---------------------+--------------------|\n     | local-hetero_linear_regression-regression |    0.312552080517407    | 0.9040310440206087 | 0.09768880303575968 | 0.9040312584426697 |\n     |  FATE-hetero_linear_regression-regression |    0.3139977881119483   | 0.9031411831961411 | 0.09859461093919598 | 0.903146386539082  |\n     |-------------------------------------------+-------------------------+--------------------+---------------------+--------------------|\n     |-------------------------------------|\n     |            Match Results            |\n     |-------------------------+-----------|\n     |          Metric         | All Match |\n     | root_mean_squared_error |    True   |\n     |         r2_score        |    True   |\n     |    mean_squared_error   |    True   |\n     |    explained_variance   |    True   |\n     |-------------------------+-----------|\n\n\n     |-------------------------------------------------------------------------------------|\n     |                             FATE Script Metrics Summary                             |\n     |--------------------+---------------------+--------------------+---------------------|\n     | Script Model Name  |         min         |        max         |         mean        |\n     |--------------------+---------------------+--------------------+---------------------|\n     |  linr_train-FATE   | -1.5305666678748353 | 1.4968292506353484 | 0.03948016870496807 |\n     | linr_validate-FATE | -1.5305666678748353 | 1.4968292506353484 | 0.03948016870496807 |\n     |--------------------+---------------------+--------------------+---------------------|\n     |---------------------------------------|\n     |   FATE Script Metrics Match Results   |\n     |----------------+----------------------|\n     |     Metric     |      All Match       |\n     |----------------+----------------------|\n     |      min       |         True         |\n     |      max       |         True         |\n     |      mean      |         True         |\n     |----------------+----------------------|\n\n\n\ncommand options\n~~~~~~~~~~~~~~~\n\nuse the following command to show help message\n\n.. code-block:: bash\n\n      fate_test benchmark-quality --help\n\n1. include:\n\n   .. code-block:: bash\n\n      fate_test benchmark-quality -i <path1 contains *benchmark.json>\n\n   will run benchmark testsuites in *path1*\n\n2. exclude:\n\n   .. code-block:: bash\n\n      fate_test benchmark-quality -i <path1 contains *benchmark.json> -e <path2 to exclude> -e <path3 to exclude> ...\n\n   will run benchmark testsuites in *path1* but not in *path2* and *path3*\n\n3. glob:\n\n   .. code-block:: bash\n\n      fate_test benchmark-quality -i <path1 contains *benchmark.json> -g "hetero*"\n\n   will run benchmark testsuites in sub directory start with *hetero* of *path1*\n\n4. tol:\n\n   .. code-block:: bash\n\n      fate_test benchmark-quality -i <path1 contains *benchmark.json> -t 1e-3\n\n   will run benchmark testsuites in *path1* with absolute tolerance of difference between metrics set to 0.001.\n   If absolute difference between metrics is smaller than *tol*, then metrics are considered\n   almost equal. Check benchmark testsuite `writing guide <#benchmark-testsuite>`_ on setting alternative tolerance.\n\n5. skip-data:\n\n   .. code-block:: bash\n\n       fate_test benchmark-quality -i <path1 contains *benchmark.json> --skip-data\n\n   will run benchmark testsuites in *path1* without uploading data specified in *benchmark.json*.\n\n6. disable-clean-data:\n\n   .. code-block:: bash\n\n       fate_test suite -i <path1 contains *benchmark.json> --disable-clean-data\n\n   will run benchmark testsuites in *path1* without removing data from storage after tasks finish\n\n7. enable-clean-data:\n\n   .. code-block:: bash\n\n       fate_test suite -i <path1 contains *benchmark.json> --enable-clean-data\n\n   will remove data from storage after finishing running benchmark testsuites\n\n8. yes:\n\n   .. code-block:: bash\n\n      fate_test benchmark-quality -i <path1 contains *benchmark.json> --yes\n\n   will run benchmark testsuites in *path1* directly, skipping double check\n\n\nbenchmark testsuite\n~~~~~~~~~~~~~~~~~~~\n\nConfiguration of jobs should be specified in a benchmark testsuite whose file name ends\nwith "\\*benchmark.json". For benchmark testsuite example,\nplease refer `here <../../examples/benchmark_quality>`_.\n\nA benchmark testsuite includes the following elements:\n\n- data: list of local data to be uploaded before running FATE jobs\n\n  - file: path to original data file to be uploaded, should be relative to testsuite or FATE installation path\n  - head: whether file includes header\n  - partition: number of partition for data storage\n  - table_name: table name in storage\n  - namespace: table namespace in storage\n  - role: which role to upload the data, as specified in fate_test.config;\n    naming format is: "{role_type}_{role_index}", index starts at 0\n\n  .. code-block:: json\n\n        "data": [\n            {\n                "file": "examples/data/motor_hetero_host.csv",\n                "head": 1,\n                "partition": 8,\n                "table_name": "motor_hetero_host",\n                "namespace": "experiment",\n                "role": "host_0"\n            }\n        ]\n\n- job group: each group includes arbitrary number of jobs with paths to corresponding script and configuration\n\n  - job: name of job to be run, must be unique within each group list\n\n    - script: path to `testing script <#testing-script>`_, should be relative to testsuite\n    - conf: path to job configuration file for script, should be relative to testsuite\n\n    .. code-block:: json\n\n       "local": {\n            "script": "./local-linr.py",\n            "conf": "./linr_config.yaml"\n       }\n\n  - compare_setting: additional setting for quality metrics comparison, currently only takes ``relative_tol``\n\n    If metrics *a* and *b* satisfy *abs(a-b) <= max(relative_tol \\* max(abs(a), abs(b)), absolute_tol)*\n    (from `math module <https://docs.python.org/3/library/math.html#math.isclose>`_),\n    they are considered almost equal. In the below example, metrics from "local" and "FATE" jobs are\n    considered almost equal if their relative difference is smaller than\n    *0.05 \\* max(abs(local_metric), abs(pipeline_metric)*.\n\n  .. code-block:: json\n\n     "linear_regression-regression": {\n         "local": {\n             "script": "./local-linr.py",\n             "conf": "./linr_config.yaml"\n         },\n         "FATE": {\n             "script": "./fate-linr.py",\n             "conf": "./linr_config.yaml"\n         },\n         "compare_setting": {\n             "relative_tol": 0.01\n         }\n     }\n\n\ntesting script\n~~~~~~~~~~~~~~\n\nAll job scripts need to have ``Main`` function as an entry point for executing jobs; scripts should\nreturn two dictionaries: first with data information key-value pairs: {data_type}: {data_name_dictionary};\nthe second contains {metric_name}: {metric_value} key-value pairs for metric comparison.\n\nBy default, the final data summary shows the output from the job named "FATE"; if no such job exists,\ndata information returned by the first job is shown. For clear presentation, we suggest that user follow\nthis general `guideline <../../examples/data/README.md#data-set-naming-rule>`_ for data set naming. In the case of multi-host\ntask, consider numbering host as such:\n\n::\n\n    {\'guest\': \'default_credit_homo_guest\',\n     \'host_1\': \'default_credit_homo_host_1\',\n     \'host_2\': \'default_credit_homo_host_2\'}\n\nReturned quality metrics of the same key are to be compared.\nNote that only **real-value** metrics can be compared.\n\nTo compare metrics of different models from the same script,\nmetrics of each model need to be wrapped into dictionary in the same format as the general metric output above.\n\nIn the returned dictionary of script, use reserved key ``script_metrics`` to indicate the collection of metrics to be compared.\n\n- FATE script: ``Main`` should have three inputs:\n\n  - config: job configuration, `JobConfig <../fate_client/pipeline/utils/tools.py#L64>`_ object loaded from "fate_test_config.yaml"\n  - param: job parameter setting, dictionary loaded from "conf" file specified in benchmark testsuite\n  - namespace: namespace suffix, user-given *namespace* or generated timestamp string when using *namespace-mangling*\n\n- non-FATE script: ``Main`` should have one or two inputs:\n\n  - param: job parameter setting, dictionary loaded from "conf" file specified in benchmark testsuite\n  - (optional) config: job configuration, `JobConfig <../fate_client/pipeline/utils/tools.py#L64>`_ object loaded from "fate_test_config.yaml"\n\nNote that ``Main`` in FATE & non-FATE scripts can also be set to take zero input argument.\n\nperformance\n-----------\n\n`Performance` sub-command is used to test efficiency of designated FATE jobs.\n\ncommand options\n~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n      fate_test performance --help\n\n1. job-type:\n\n   .. code-block:: bash\n\n      fate_test performance -t intersect\n\n   will run testsuites from intersect sub-directory (set in config) in the default performance directory;\n   note that only one of ``task`` and ``include`` is needed\n\n2. include:\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json>; note that only one of ``task`` and ``include`` needs to be specified.\n\n   will run testsuites in *path1*.\n   Note that only one of ``task`` and ``include`` needs to be specified;\n   when both are given, path from ``include`` takes priority.\n\n3. replace:\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -r \'{"maxIter": 5}\'\n\n   will find all key-value pair with key "maxIter" in `data conf` or `conf` or `dsl` and replace the value with 5\n\n4. timeout:\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -m 3600\n\n   will run testsuites in *path1* and timeout when job does not finish within 3600s; if tasks need more time, use a larger threshold\n\n5. max-iter:\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -e 5\n\n   will run testsuites in *path1* with all values to key "max_iter" set to 5\n\n6. max-depth\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -d 4\n\n   will run testsuites in *path1* with all values to key "max_depth" set to 4\n\n7. num-trees\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -n 5\n\n   will run testsuites in *path1* with all values to key "num_trees" set to 5\n\n8. task-cores\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -p 4\n\n   will run testsuites in *path1* with EGGROLL "task_cores" set to 4\n\n9. update-job-parameters\n\n   .. code-block:: bash\n\n      fate_test performance -i <path1 contains *testsuite.json> -j {}\n\n   will run testsuites in *path1* with respective job parameters set to provided values\n\n10. update-component-parameters\n\n    .. code-block:: bash\n\n       fate_test performance -i <path1 contains *testsuite.json> -c {}\n\n    will run testsuites in *path1* with respective component parameters set to provided values\n\n11. skip-data:\n\n    .. code-block:: bash\n\n        fate_test performance -i <path1 contains *testsuite.json> --skip-data\n\n    will run testsuites in *path1* without uploading data specified in *testsuite.json*.\n\n12. disable-clean-data:\n\n    .. code-block:: bash\n\n       fate_test performance -i <path1 contains *testsuite.json> --disable-clean-data\n\n    will run testsuites in *path1* without removing data from storage after tasks finish\n\n13. yes:\n\n    .. code-block:: bash\n\n       fate_test performance -i <path1 contains *testsuite.json> --yes\n\n    will run testsuites in *path1* directly, skipping double check\n\n\ndata\n----\n\n`Data` sub-command is used for upload, delete, and generate dataset.\n\ncommand options\n~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n      fate_test data --help\n\n1. include:\n\n   .. code-block:: bash\n\n      fate_test data [upload|delete] -i <path1 contains *testsuite.json | *benchmark.json>\n\n   will upload/delete dataset in testsuites in *path1*\n\n2. exclude:\n\n   .. code-block:: bash\n\n      fate_test data [upload|delete] -i <path1 contains *testsuite.json | *benchmark.json> -e <path2 to exclude> -e <path3 to exclude> ...\n\n   will upload/delete dataset in testsuites in *path1* but not in *path2* and *path3*\n\n3. glob:\n\n   .. code-block:: bash\n\n      fate_test data [upload|delete] -i <path1 contains \\*testsuite.json | \\*benchmark.json> -g "hetero*"\n\n   will upload/delete dataset in testsuites in sub directory start with *hetero* of *path1*\n\ngenerate command options\n~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. code-block:: bash\n\n      fate_test data --help\n\n1. include:\n\n   .. code-block:: bash\n\n      fate_test data generate -i <path1 contains *testsuite.json | *benchmark.json>\n\n   will generate dataset in testsuites in *path1*; note that only one of ``type`` and ``include`` is needed\n\n2. host-data-type:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -ht {tag-value | dense | tag }\n\n   will generate dataset in testsuites *path1* where host data are of selected format\n\n3. sparsity:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -s 0.2\n\n   will generate dataset in testsuites in *path1* with sparsity at 0.1; useful for tag-formatted data\n\n4. encryption-type:\n\n   .. code-block:: bash\n\n      fate_test data generate -i <path1 contains *testsuite.json | *benchmark.json> -p {sha256 | md5}\n\n   will generate dataset in testsuites in *path1* with hash id using SHA256 method\n\n5. match-rate:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -m 1.0\n\n   will generate dataset in testsuites in *path1* where generated host and guest data have intersection rate of 1.0\n\n6. guest-data-size:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -ng 10000\n\n   will generate dataset in testsuites *path1* where guest data each have 10000 entries\n\n7. host-data-size:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -nh 10000\n\n   will generate dataset in testsuites *path1* where host data have 10000 entries\n\n8. guest-feature-num:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -fg 20\n\n   will generate dataset in testsuites *path1* where guest data have 20 features\n\n9. host-feature-num:\n\n   .. code-block:: bash\n\n      fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -fh 200\n\n   will generate dataset in testsuites *path1* where host data have 200 features\n\n10. output-path:\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -o <path2>\n\n    will generate dataset in testsuites *path1* and write file to *path2*\n\n11. force:\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -o <path2> --force\n\n    will generate dataset in testsuites *path1* and write file to *path2*;\n    will overwrite existing file(s) if designated file name found under *path2*\n\n12. split-host:\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> -nh 10000 --split-host\n\n    will generate dataset in testsuites *path1*; 10000 entries will be divided equally among all host data sets\n\n13. upload-data\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> --upload-data\n\n    will generate dataset in testsuites *path1* and upload generated data for all parties to FATE\n\n14. remove-data\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> --remove-data\n\n    (effective with ``upload-data`` set to True) will delete generated data after generate and upload dataset in testsuites *path1*\n\n15. use-local-data\n\n    .. code-block:: bash\n\n       fate_test suite -i <path1 contains *testsuite.json | *benchmark.json> --use-local-data\n\n    (effective with ``upload-data`` set to True) will generate dataset in testsuites *path1* and upload data from local server;\n    use this option if flow and data storage are deployed to the same server\n\n',
    'author': 'FederatedAI',
    'author_email': 'contact@FedAI.org',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://fate.fedai.org/',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.6,<4.0',
}


setup(**setup_kwargs)
