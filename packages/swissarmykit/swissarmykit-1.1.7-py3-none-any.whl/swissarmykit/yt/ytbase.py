import sys
import traceback
from pprint import pprint
from datetime import datetime

from swissarmykit.db.mongodb import BaseDocument
from swissarmykit.data.JsonData import JsonData
from swissarmykit.utils.numberutils import NumberUtils
from swissarmykit.utils.dateutils import DateUtils
from swissarmykit.utils.loggerutils import LoggerUtils
from mongoengine.queryset.visitor import Q as MQ


try:
    from definitions_prod import *
except Exception as e:
    pass

class YoutubeBase: # extends RequestBase, BaseDocument
    
    def __init__(self):
        self.log = LoggerUtils.instance()

    @classmethod
    def _save_url_channel(cls, url, d_, **kwargs): # type: (str, any, any) -> BaseDocument or None
        if 'www' not in url:
            url = url.replace('youtube.com', 'www.youtube.com')
            if 'www' not in url: raise Exception('no wwww')

        if 'https' not in url:
            url = url.replace('http', 'https')
            if 'https' not in url: raise Exception('no https')

        # if url in ExceptionChannel.urls:
        #     raise Exception('Abnormal', url, d_)

        if d_ and d_.get('description') and  'This channel was generated automatically by YouTube' in d_.get('description'):
            print('ERROR: Skip channel auto-generated by Youtube', url)
            return None

        return cls.save_url(url, **kwargs)


    @classmethod
    def get_json_from_html(cls, html):
        # if html and 'window["ytInitialData"] = ' in html:
        #     html = html.split('window["ytInitialData"] = ')[-1].split('window["ytInitialPlayerResponse"]')[0].rsplit(';', 1)[0]
        if html and 'var ytInitialData = ' in html:
            html = html.split('var ytInitialData = ')[-1].split(';</script>')[0]
            if not html.endswith('}'):
                raise Exception('fail')
        else:
            if 'g-recaptcha' in html:
                print('ERROR: g-recaptcha')
            raise Exception('fail')
        return html

    def _parse_vid_detail(self, item: BaseDocument, limit=-1):
        try:
            html = item.get_html()
            if not html or len(html) < 500:
                if limit == 1: print(item.url, html)
                if html and JsonData.is_json(html):
                    print('_', end='', flush=True)
                    return {'is_private': True, 're_update': 0}, item.url
                print('x', end='', flush=True)
                return None, None

            d_ = JsonData(json_html=html)

            content = d_.get_list('contents.twoColumnWatchNextResults.results.results.contents')

            covid = content[0].get('itemSectionRenderer.contents')
            index = 0
            if covid: index += 1

            primary = content[index].get('videoPrimaryInfoRenderer')
            meta_desc = content[index + 1].get('videoSecondaryInfoRenderer')

            owner = meta_desc.get('owner.videoOwnerRenderer')
            action = primary.get('videoActions.menuRenderer.topLevelButtons')

            like = action[0].get('toggleButtonRenderer.defaultText.accessibility.accessibilityData.label').get_value(default='').split(' ')[0]
            dislike = action[1].get('toggleButtonRenderer.defaultText.accessibility.accessibilityData.label').get_value(default='').split(' ')[0]
            like = NumberUtils.digits_to_number(like if like != 'No' else '')
            dislike = NumberUtils.digits_to_number(dislike if dislike != 'No' else '')

            views = primary.get('viewCount.videoViewCountRenderer.viewCount.simpleText').val
            publishedTimeText = primary.get('dateText.simpleText').val
            if views and views != 'No views':
                views = int(views.split(' ')[0].replace(',', ''))
            else:
                views = 0

            channel_url = owner.get('title.runs[0].navigationEndpoint.commandMetadata.webCommandMetadata.url').val
            published_date = primary.get('dateText.simpleText').val
            description = '\n'.join([r.get('text').val for r in meta_desc.get_list('description.runs')])

            if published_date:
                published_date = ' '.join(published_date.split(' ')[-3:])
                if 'hour' in published_date or 'minute' in published_date:
                    published_date = datetime.now()
                else:
                    published_date = DateUtils.convert_str_datetime(published_date)

            data = {'like': like, 'dislike': dislike,
                    'views': views,
                    'viewCount': views,
                    'thumbnail': 'https://i.ytimg.com/vi/%s/hqdefault.jpg' % item.url,
                    'description': description,
                    'published_date': published_date,
                    'channelId': channel_url.split('/')[-1],
                    'videoId': item.url,
                    'publishedTimeText': publishedTimeText,
                    're_update': 0,
                    }

            # if limit != -1 and limit < 10: pprint(data); print('https://www.youtube.com/watch?v=%s' % item.url)

            print('.', end='', flush=True)
            return data, item.url

        except Exception as e:
            traceback.print_exc(file=sys.stdout)
            self.log.info(e, 'url: ', 'https://www.youtube.com/watch?v=%s' % item.url, item.get_id_offset())

        return None, None

    def parse_detail_from_server(self, limit=-1, offset=0, cls=None):
        if cls:
            ytvideo_cross = cls
        else:
            ytvideo_cross = BaseDocument.get_class('ytvideo', db_name='ml', html_path='Z:/html')

        qs = ytvideo_cross.get_one(limit=limit, offset=offset, filters_combination=(MQ(updated_at=None) | MQ(re_update=1)))
        print('INFO: Total: ', qs.count())

        for item in qs:
            # print(item)
            try:
                data, url = self._parse_vid_detail(item, limit)
                if data: item.save_attr(data, update_modified_date=True)
            except Exception as e:
                if limit != -1 and limit < 10: traceback.print_exc(file=sys.stdout)
                self.log.error(e, item.url, item.get_id_offset())